# Knowledge Pipeline v4.0.0 Release Guide

## Overview

Version 4.0.0 introduces comprehensive prompt attribution and enhanced Notion formatting capabilities. This release focuses on transparency, traceability, and improved content presentation.

## Major Changes from v3.x

### 1. Prompt Attribution System

The pipeline now tracks and displays detailed information about every AI prompt used in content processing:

- **Prompt Tracking**: Every AI analysis includes metadata about the prompt used, version, temperature, and model
- **Attribution Display**: A collapsible attribution section appears in Notion pages showing:
  - Number of prompts used
  - Average quality score
  - Total processing time
  - Token usage
  - Direct links to prompt configurations

### 2. Enhanced Notion Formatting

Content is now formatted with improved visual hierarchy and mobile responsiveness:

- **Quality Indicators**: Visual indicators (⭐/✓/•/!) based on content quality scores
- **Executive Dashboard**: Structured insights with action items and key takeaways
- **Collapsible Sections**: Better organization with toggles for different content types
- **Mobile Optimization**: Responsive design for better mobile viewing

### 3. Prompt Configuration Database

Prompts are now managed through a Notion database instead of YAML files:

- **Database-Backed**: All prompts stored in Notion with version control
- **Content-Type Specific**: Different prompts for different content types (Market News, Technical Docs, etc.)
- **Web Search Integration**: Prompts can enable web search for current information
- **Temperature Control**: Fine-tuned temperature settings per prompt

## Architecture Changes

### Core Components

```
src/
├── core/
│   ├── prompt_config_enhanced.py  # New enhanced prompt configuration
│   └── notion_client.py           # Updated with text truncation
├── enrichment/
│   ├── pipeline_processor.py      # Main processor with attribution
│   └── content_tagger.py          # Enhanced with tag caching
└── formatters/
    ├── prompt_aware_notion_formatter.py  # Primary formatter
    └── enhanced_prompt_attribution.py    # Attribution formatting
```

### Key Classes

1. **EnhancedPromptConfig** (`prompt_config_enhanced.py`)
   - Manages prompt database connections
   - Caches prompts for performance
   - Handles prompt selection logic

2. **PromptAwareNotionFormatter** (`prompt_aware_notion_formatter.py`)
   - Creates rich Notion blocks with attribution
   - Handles quality indicators and formatting
   - Mobile-responsive design

3. **PipelineProcessor** (`pipeline_processor.py`)
   - Enhanced with prompt tracking
   - Quality scoring system
   - Validation and error handling

## Configuration

### Required Environment Variables

```bash
# Notion Configuration
NOTION_TOKEN=your_notion_api_token
NOTION_DATABASE_ID=your_content_database_id
NOTION_PROMPT_DB_ID=your_prompt_database_id  # NEW in v4.0

# Feature Flags
USE_ENHANCED_FORMATTING=true  # Enable new formatting
USE_ENHANCED_ATTRIBUTION=true  # Enable prompt attribution

# OpenAI Configuration  
OPENAI_API_KEY=your_openai_api_key
OPENAI_MODEL=gpt-4o-mini  # Default model
```

### Prompt Database Schema

The Notion prompt database must have these properties:

| Property | Type | Description |
|----------|------|-------------|
| Name | Title | Prompt identifier (e.g., "summarizer/Market News") |
| Prompt | Text | The actual prompt template |
| Temperature | Number | Temperature setting (0.0-1.0) |
| Version | Text | Version number (e.g., "1.0") |
| Active | Checkbox | Whether prompt is active |
| Web Search | Checkbox | Enable web search for this prompt |
| Max Tokens | Number | Maximum response tokens |

## Usage

### Basic Pipeline Run

```bash
# Run the enhanced pipeline
python scripts/run_pipeline.py

# The pipeline will:
# 1. Load prompts from Notion database
# 2. Process content with attribution tracking
# 3. Generate formatted output with quality indicators
# 4. Add attribution section to each page
```

### Processing Flow

1. **Content Ingestion**: Files are loaded from Google Drive or local sources
2. **Classification**: Advanced classifier determines content type
3. **Prompt Selection**: Appropriate prompts selected based on content type
4. **AI Analysis**: Content processed with tracking of all prompts used
5. **Quality Scoring**: Each analysis receives a quality score
6. **Formatting**: Content formatted with attribution and quality indicators
7. **Notion Upload**: Formatted content with attribution saved to Notion

## Quality Scoring System

Content quality is scored on multiple factors:

- **Completeness**: Are all expected sections present?
- **Depth**: How thorough is the analysis?
- **Clarity**: Is the content well-structured?
- **Actionability**: Are insights practical?

Scores map to visual indicators:
- 9.0+ = ⭐ (Excellent)
- 7.0+ = ✓ (Good)
- 5.0+ = • (Fair)
- <5.0 = ! (Needs Review)

## API Endpoints

The system includes a FastAPI-based management API:

```python
# List all prompts
GET /prompts?active_only=true&content_type=Market+News

# Get analytics
GET /analytics/performance?start_date=2024-01-01

# Submit feedback
POST /feedback
{
  "prompt_id": "prompt-uuid",
  "rating": 5,
  "feedback": "Great results"
}
```

## Migration from v3.x

### Automatic Migration

The system handles most migration automatically:

1. Legacy content continues to work
2. New content gets attribution
3. Prompts loaded from both YAML (legacy) and Notion (new)

### Manual Steps

1. **Create Prompt Database**: Set up a new Notion database with required schema
2. **Set Environment Variable**: Add `NOTION_PROMPT_DB_ID`
3. **Migrate Prompts**: Copy YAML prompts to Notion database (optional)

### Rollback

To rollback to v3.x behavior:

```bash
# Disable new features
USE_ENHANCED_FORMATTING=false
USE_ENHANCED_ATTRIBUTION=false
```

## Performance Optimizations

### Caching
- Prompt configurations cached for 5 minutes
- Tag lists cached to reduce API calls
- Smart text chunking for large documents

### Batch Processing
- Documents processed in configurable batches
- Automatic retry with exponential backoff
- Error recovery without losing progress

### Text Handling
- Automatic truncation of oversized text (2000 char limit)
- Semantic chunking preserves markdown structure
- Nested content optimization

## Troubleshooting

### Common Issues

1. **"body failed validation" errors**
   - Usually means text exceeds 2000 character limit
   - Check for empty children arrays in blocks
   - Ensure quote blocks don't have children property

2. **Missing attribution**
   - Verify `USE_ENHANCED_ATTRIBUTION=true`
   - Check prompt database connection
   - Ensure prompts have required properties

3. **Slow processing**
   - Enable caching features
   - Reduce batch size for large documents
   - Check API rate limits

### Debug Mode

Enable detailed logging:

```python
# In pipeline_processor.py
logger.setLevel(logging.DEBUG)
```

## Best Practices

1. **Prompt Management**
   - Version prompts when making changes
   - Test prompts on sample content first
   - Monitor quality scores for prompt effectiveness

2. **Content Processing**
   - Process similar content types in batches
   - Use appropriate batch sizes (10-50 items)
   - Monitor token usage to control costs

3. **Quality Assurance**
   - Review low-scoring content (< 5.0)
   - Collect feedback on prompt performance
   - Iterate on prompts based on results

## Limitations

- No true parallel processing (sequential batch processing only)
- Notion API limits (2000 chars per text block)
- Rate limiting on OpenAI API calls
- Maximum 100 blocks per toggle section

## Future Enhancements

Planned for future releases:
- True parallel processing with asyncio
- Advanced caching strategies
- Prompt A/B testing automation
- Real-time quality monitoring dashboard