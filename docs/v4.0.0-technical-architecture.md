# Knowledge Pipeline v4.0.0 Technical Architecture

## System Architecture

### Component Overview

```
┌─────────────────────────────────────────────────────────────┐
│                      Input Sources                           │
├─────────────────┬──────────────────┬───────────────────────┤
│  Google Drive   │  Local Files     │  Direct Upload        │
└────────┬────────┴──────────┬───────┴───────────┬───────────┘
         │                   │                   │
         v                   v                   v
┌─────────────────────────────────────────────────────────────┐
│                    Ingestion Layer                          │
│  ┌─────────────┐  ┌──────────────┐  ┌─────────────────┐   │
│  │   Drive     │  │    Local     │  │   PDF           │   │
│  │  Ingester   │  │  Uploader    │  │  Processor      │   │
│  └─────────────┘  └──────────────┘  └─────────────────┘   │
└─────────────────────────────┬───────────────────────────────┘
                              │
                              v
┌─────────────────────────────────────────────────────────────┐
│                   Enrichment Pipeline                       │
│  ┌─────────────────────────────────────────────────────┐   │
│  │            Pipeline Processor (Enhanced)             │   │
│  ├─────────────────────────────────────────────────────┤   │
│  │ • Advanced Classification                            │   │
│  │ • Prompt Selection & Tracking                       │   │
│  │ • AI Analysis Orchestration                         │   │
│  │ • Quality Scoring                                   │   │
│  │ • Attribution Management                            │   │
│  └─────────────────────────────────────────────────────┘   │
└─────────────────────────────┬───────────────────────────────┘
                              │
                              v
┌─────────────────────────────────────────────────────────────┐
│                   Formatting Layer                          │
│  ┌─────────────────────────────────────────────────────┐   │
│  │        PromptAwareNotionFormatter                   │   │
│  ├─────────────────────────────────────────────────────┤   │
│  │ • Rich Block Creation                               │   │
│  │ • Attribution Formatting                            │   │
│  │ • Quality Indicators                                │   │
│  │ • Mobile Optimization                               │   │
│  └─────────────────────────────────────────────────────┘   │
└─────────────────────────────┬───────────────────────────────┘
                              │
                              v
┌─────────────────────────────────────────────────────────────┐
│                      Storage Layer                          │
│  ┌─────────────────┐  ┌──────────────┐  ┌─────────────┐   │
│  │  Notion Content │  │ Notion Prompt│  │   Local     │   │
│  │    Database     │  │   Database   │  │   Cache     │   │
│  └─────────────────┘  └──────────────┘  └─────────────┘   │
└─────────────────────────────────────────────────────────────┘
```

## Core Classes and Responsibilities

### 1. EnhancedPromptConfig (`core/prompt_config_enhanced.py`)

**Purpose**: Manages prompt configurations from both YAML files and Notion database.

```python
class EnhancedPromptConfig:
    def __init__(self, 
                 yaml_dir: Optional[str] = None,
                 notion_client: Optional[NotionClient] = None,
                 prompt_db_id: Optional[str] = None):
        # Dual-source prompt management
        self.yaml_prompts = {}      # Legacy YAML prompts
        self.notion_prompts = {}    # New database prompts
        self.cache_ttl = 300        # 5-minute cache
```

**Key Methods**:
- `get_prompt()`: Retrieves prompt with Notion priority over YAML
- `refresh_notion_cache()`: Updates cached prompts from database
- `get_all_active_prompts()`: Returns all enabled prompts

### 2. PipelineProcessor (`enrichment/pipeline_processor.py`)

**Purpose**: Main orchestrator for content enrichment with attribution tracking.

```python
class PipelineProcessor:
    def __init__(self, config: PipelineConfig, notion_client: NotionClient):
        # Enhanced features
        self.use_enhanced_formatting = True
        self.use_enhanced_attribution = True
        self.prompt_tracking = {}  # Tracks all prompts used
        
    def process_batch(self, batch_size: int = 10) -> Dict[str, Any]:
        # Sequential batch processing with tracking
        # No parallel execution - processes items one by one
```

**Key Features**:
- Prompt usage tracking per analyzer
- Quality score calculation
- Attribution block creation
- Validation and error recovery

### 3. PromptAwareNotionFormatter (`formatters/prompt_aware_notion_formatter.py`)

**Purpose**: Creates rich Notion blocks with attribution and quality indicators.

```python
class PromptAwareNotionFormatter:
    def format_with_attribution(self,
                               content: str,
                               content_type: str,
                               metadata: PromptMetadata,
                               include_attribution: bool = True) -> List[Dict]:
        # Generates formatted blocks with attribution
```

**Key Features**:
- Mobile-responsive design
- Quality indicator badges
- Collapsible attribution sections
- Executive dashboards
- Semantic content structuring

## Data Flow

### 1. Prompt Selection Flow

```
Content Type Detection → Prompt Database Query → Cache Check → 
Prompt Template → AI Analysis → Attribution Tracking
```

### 2. Attribution Data Structure

```python
{
    "analyzer_name": "summarizer",
    "prompt_id": "2366d7f5-23bc-8177-8877-cce425d8dc3f",
    "prompt_version": "1.0",
    "temperature": 0.4,
    "model": "gpt-4o-mini",
    "quality_score": 8.5,
    "processing_time": 2.3,
    "token_usage": {
        "prompt_tokens": 1200,
        "completion_tokens": 800,
        "total_tokens": 2000
    },
    "web_search_used": True
}
```

### 3. Quality Scoring Algorithm

```python
def calculate_quality_score(self, result: EnrichmentResult) -> float:
    scores = []
    
    # Completeness (40%)
    if result.summary: scores.append(0.4)
    
    # Depth (30%)
    insight_score = min(len(result.insights) / 5, 1.0) * 0.3
    scores.append(insight_score)
    
    # Structure (20%)
    if result.action_items: scores.append(0.2)
    
    # Clarity (10%)
    if result.key_quotes: scores.append(0.1)
    
    return sum(scores) * 10  # Scale to 0-10
```

## Database Schemas

### Notion Content Database

| Property | Type | Description |
|----------|------|-------------|
| Name | Title | Document title |
| Status | Select | Inbox/Processing/Enriched/Failed |
| Content Type | Select | Classified content type |
| Source | Select | Drive/Upload/Web |
| Quality Score | Number | 0-10 quality rating |
| Processing Time | Number | Seconds to process |
| Created | Date | Ingestion timestamp |

### Notion Prompt Database

| Property | Type | Description |
|----------|------|-------------|
| Name | Title | analyzer/content_type format |
| Prompt | Text | Prompt template with variables |
| Temperature | Number | 0.0-1.0 OpenAI temperature |
| Max Tokens | Number | Response token limit |
| Version | Text | Semantic version (1.0, 1.1, etc) |
| Active | Checkbox | Enable/disable prompt |
| Web Search | Checkbox | Enable web search |
| Created By | Person | Prompt author |
| Last Modified | Date | Last update timestamp |

## Performance Characteristics

### Processing Metrics

- **Average document processing**: 3-5 seconds
- **Batch size**: 10-50 documents (configurable)
- **API rate limiting**: 0.5s delay between calls
- **Cache TTL**: 5 minutes for prompts, 10 minutes for tags

### Memory Usage

- **Document chunking**: 1900 chars per block (Notion limit 2000)
- **Batch memory**: ~50MB per 10 documents
- **Prompt cache**: ~1MB for typical database

### Bottlenecks

1. **Sequential Processing**: No parallel execution
2. **API Rate Limits**: OpenAI and Notion API constraints
3. **Large Documents**: Chunking overhead for 50k+ char documents
4. **Network Latency**: Multiple API calls per document

## Error Handling

### Validation Pipeline

```python
# 1. Block validation before Notion API
validated_blocks = self._validate_notion_blocks(blocks)

# 2. Text truncation for limits
if len(text) > 1900:
    text = text[:1897] + "..."

# 3. Empty children removal
if "children" in block and len(block["children"]) == 0:
    del block["children"]
```

### Recovery Mechanisms

1. **Retry with backoff**: 3 attempts with exponential delay
2. **Partial failure handling**: Continue batch on single item failure
3. **Error status tracking**: Failed items marked in database
4. **Validation warnings**: Pre-flight checks before API calls

## Configuration Management

### Environment Variables

```bash
# Core Settings
NOTION_TOKEN=secret_xxx
NOTION_DATABASE_ID=xxx
NOTION_PROMPT_DB_ID=xxx  # New in v4.0

# Feature Flags
USE_ENHANCED_FORMATTING=true
USE_ENHANCED_ATTRIBUTION=true
ENABLE_PROMPT_CACHING=true

# Performance Tuning
BATCH_SIZE=10
RATE_LIMIT_DELAY=0.5
CACHE_TTL_MINUTES=5
MAX_RETRIES=3
```

### Feature Toggle System

```python
# Runtime feature detection
if os.getenv('USE_ENHANCED_FORMATTING', 'true').lower() == 'true':
    self.formatter = PromptAwareNotionFormatter()
else:
    self.formatter = LegacyFormatter()
```

## Integration Points

### API Endpoints (FastAPI)

```python
# Prompt Management API
GET  /prompts              # List all prompts
GET  /prompts/{id}         # Get specific prompt
POST /prompts/{id}/feedback # Submit feedback

# Analytics API  
GET  /analytics/performance # Processing metrics
GET  /analytics/quality     # Quality score trends
GET  /analytics/prompts     # Prompt usage stats
```

### External Services

1. **OpenAI API**: GPT-4o-mini for analysis
2. **Notion API**: Content and prompt storage
3. **Google Drive API**: Document ingestion
4. **Web Search**: Optional current information

## Limitations and Constraints

### Technical Limitations

1. **No Parallel Processing**: All operations are sequential
2. **Notion API Limits**: 
   - 2000 chars per text block
   - 100 blocks per API call
   - 3 requests per second
3. **Memory Constraints**: Large batches may cause memory issues
4. **No Real-time Updates**: Batch processing only

### Design Decisions

1. **Sequential over Parallel**: Simpler error handling and debugging
2. **Dual Prompt Sources**: Backward compatibility with YAML
3. **Quality over Speed**: Emphasis on attribution and tracking
4. **Notion-Native**: Leveraging Notion's UI capabilities

## Security Considerations

1. **Token Storage**: Environment variables only
2. **No Credential Persistence**: OAuth tokens in memory
3. **Input Validation**: All user inputs sanitized
4. **API Key Rotation**: Supported via env vars
5. **Error Message Sanitization**: No secrets in logs